{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tdualCR3-cR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import nltk\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJsEM5xeO6_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "c31fe310-a4ca-4a2f-b361-c3195afef8a0"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFURn8Wx6b78",
        "colab_type": "text"
      },
      "source": [
        "## Data base is taken from UCI machine learning repositary\n",
        "### data name is 'SMS Spam collection data set'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R36MRFqw6ZKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df =pd.read_table('/content/SMSSpamCollection', header=None, encoding ='utf-8')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yzoLgiSBd7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "16adbb58-f421-4b95-a0ab-adf58ebb933f"
      },
      "source": [
        "#read data frame\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       5572 non-null   object\n",
            " 1   1       5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "None\n",
            "      0                                                  1\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW5oam3aFSle",
        "colab_type": "text"
      },
      "source": [
        "#Distribution of classes is skew --> ham is way more higher than spam, we have to normalize to get better pridiction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03RkiYOyCh_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "00053c13-b99d-42a5-ed45-a5f842ad44c0"
      },
      "source": [
        "# see the number of ham(not spam) and spam\n",
        "#df[0] give column 0 0f data frame\n",
        "classes = df[0]\n",
        "print(classes)\n",
        "print(classes.value_counts())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        ham\n",
            "1        ham\n",
            "2       spam\n",
            "3        ham\n",
            "4        ham\n",
            "        ... \n",
            "5567    spam\n",
            "5568     ham\n",
            "5569     ham\n",
            "5570     ham\n",
            "5571     ham\n",
            "Name: 0, Length: 5572, dtype: object\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B93zyFh-D_NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing of data\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYep_725Fu-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "d0204887-bf2a-4961-d5e6-5d0bc90866ae"
      },
      "source": [
        "#Initialization of label encoder\n",
        "encoder =LabelEncoder()\n",
        "Y =encoder.fit_transform(classes)\n",
        "print(classes[:10])\n",
        "print(Y[:10])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     ham\n",
            "1     ham\n",
            "2    spam\n",
            "3     ham\n",
            "4     ham\n",
            "5    spam\n",
            "6     ham\n",
            "7     ham\n",
            "8    spam\n",
            "9    spam\n",
            "Name: 0, dtype: object\n",
            "[0 0 1 0 0 1 0 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub3rGIglG4jz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "10360be2-4202-4064-da45-be901c15a1a5"
      },
      "source": [
        "#store sms\n",
        "text_messages =df[1]\n",
        "print(text_messages[:10])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    Go until jurong point, crazy.. Available only ...\n",
            "1                        Ok lar... Joking wif u oni...\n",
            "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3    U dun say so early hor... U c already then say...\n",
            "4    Nah I don't think he goes to usf, he lives aro...\n",
            "5    FreeMsg Hey there darling it's been 3 week's n...\n",
            "6    Even my brother is not like to speak with me. ...\n",
            "7    As per your request 'Melle Melle (Oru Minnamin...\n",
            "8    WINNER!! As a valued network customer you have...\n",
            "9    Had your mobile 11 months or more? U R entitle...\n",
            "Name: 1, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zLSkRSRIAv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Regular expression to replace email address,url and other\n",
        "#replace email adress\n",
        "# Replace email addresses with 'email'\n",
        "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
        "                                 'emailaddress')\n",
        "\n",
        "# Replace URLs with 'webaddress'\n",
        "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
        "                                  'webaddress')\n",
        "\n",
        "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
        "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
        "    \n",
        "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
        "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
        "                                  'phonenumbr')\n",
        "    \n",
        "# Replace numbers with 'numbr'\n",
        "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Al4rYaLTRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove punctuation\n",
        "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
        "\n",
        "# Replace whitespace between terms with a single space\n",
        "processed = processed.str.replace(r'\\s+', ' ')\n",
        "\n",
        "# Remove leading and trailing whitespace\n",
        "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS0QSPqvLaJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "5efa675d-ec04-4887-f755-121b320db77a"
      },
      "source": [
        "# change words to lower case - Hello, HELLO, hello are all the same word\n",
        "processed = processed.str.lower()\n",
        "print(processed)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       go until jurong point crazy available only in ...\n",
            "1                                 ok lar joking wif u oni\n",
            "2       free entry in numbr a wkly comp to win fa cup ...\n",
            "3             u dun say so early hor u c already then say\n",
            "4       nah i don t think he goes to usf he lives arou...\n",
            "                              ...                        \n",
            "5567    this is the numbrnd time we have tried numbr c...\n",
            "5568                  will ü b going to esplanade fr home\n",
            "5569    pity was in mood for that so any other suggest...\n",
            "5570    the guy did some bitching but i acted like i d...\n",
            "5571                            rofl its true to its name\n",
            "Name: 1, Length: 5572, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhzs2dtLLpoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBSl0ojcL3yF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove stop words from text messages\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    term for term in x.split() if term not in stop_words))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quWoBhNaNPcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove word stems using a Porter stemmer\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    ps.stem(term) for term in x.split()))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUE655oTNTIb",
        "colab_type": "text"
      },
      "source": [
        "#Feature generating "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNvKyzsBOZaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word tokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# create bag-of-words\n",
        "all_words = []\n",
        "\n",
        "for message in processed:\n",
        "    words = word_tokenize(message)\n",
        "    for w in words:\n",
        "        all_words.append(w)\n",
        "        \n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3AeRUIbOnc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c9e145eb-d17e-415e-9e24-b0ed7d2653c5"
      },
      "source": [
        "#print the total number of words and the 15 most common words\n",
        "print('Number of words: {}'.format(len(all_words)))\n",
        "print('Most common words: {}'.format(all_words.most_common(15)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words: 6579\n",
            "Most common words: [('numbr', 2648), ('u', 1207), ('call', 674), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('moneysymbnumbr', 303), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpKxUYgEPc6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the 1500 most common words as features\n",
        "word_features = list(all_words.keys())[:1500]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghgFYgcAPmb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d9264ea9-1f3d-401a-9b68-c517393c76d2"
      },
      "source": [
        "# The find_features function will determine which of the 1500 word features are contained in the review\n",
        "def find_features(message):\n",
        "    words = word_tokenize(message)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features[word] = (word in words)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Lets see an example!\n",
        "features = find_features(processed[0])\n",
        "for key, value in features.items():\n",
        "    if value == True:\n",
        "        print (key)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go\n",
            "jurong\n",
            "point\n",
            "crazi\n",
            "avail\n",
            "bugi\n",
            "n\n",
            "great\n",
            "world\n",
            "la\n",
            "e\n",
            "buffet\n",
            "cine\n",
            "got\n",
            "amor\n",
            "wat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2oW2znlSWMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets do it for all the messages\n",
        "messages = zip(processed, Y)\n",
        "\n",
        "# define a seed for reproducibility\n",
        "seed = 1\n",
        "np.random.seed = seed\n",
        "# call find_features function for each SMS message\n",
        "featuresets = [(find_features(text), label) for (text, label) in messages]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhfS8EwVLxbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can split the featuresets into training and testing datasets using sklearn\n",
        "from sklearn import model_selection\n",
        "\n",
        "# split the data into training and testing datasets\n",
        "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkzoPKL9L50e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b2ca2642-c993-464a-a195-0aeee9768dfb"
      },
      "source": [
        "print(len(training))\n",
        "print(len(testing))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4179\n",
            "1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iKyAYgeL-EP",
        "colab_type": "text"
      },
      "source": [
        "Scikit-Learn Classifiers with NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmQg-PlIMFVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebc6e737-5fdb-4903-bf6c-85401b697523"
      },
      "source": [
        "# We can use sklearn algorithms in NLTK\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
        "\n",
        "# train the model on the training data\n",
        "model.train(training)\n",
        "\n",
        "# and test on the testing dataset!\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\n",
        "print(\"SVC Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC Accuracy: 98.63603732950466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqpoTZKFMNrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "a98acb41-bf9a-4249-ffcf-acc1b1f54d4e"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Define models to train\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter = 100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "\n",
        "models = zip(names, classifiers)\n",
        "\n",
        "for name, model in models:\n",
        "    nltk_model = SklearnClassifier(model)\n",
        "    nltk_model.train(training)\n",
        "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
        "    print(\"{} Accuracy: {}\".format(name, accuracy))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors Accuracy: 94.11342426417804\n",
            "Decision Tree Accuracy: 97.48743718592965\n",
            "Random Forest Accuracy: 98.85139985642498\n",
            "Logistic Regression Accuracy: 98.63603732950466\n",
            "SGD Classifier Accuracy: 98.49246231155779\n",
            "Naive Bayes Accuracy: 98.63603732950466\n",
            "SVM Linear Accuracy: 98.63603732950466\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}